{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [U-Net Segmentation Approach to Cancer Diagnosis](https://www.kaggle.com/c/data-science-bowl-2017#tutorial)\n",
    "*approach to predicting whether a CT scan is of a patient who either has or will develop cancer within the next 12 months or not*\n",
    "\n",
    "General Approach:\n",
    "1. train a network to segment out potentially cancerous nodules\n",
    "2. use the characteristics of that segmentation to make predictions about the diagnosis of the scanned patient within a 12 month time frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Instructions\n",
    "1. **pydicom** (dicom): type in anaconda command prompt: `pip install pydicom` ([reference](http://pydicom.readthedocs.io/en/latest/getting_started.html))\n",
    "2. **SimpleITK**: type in anaconda command prompt: `conda install -c https://conda.anaconda.org/simpleitk SimpleITK` ([reference](https://itk.org/Wiki/SimpleITK/GettingStarted))\n",
    "3. **xgboost**: type in anaconda command prompt: `pip install xgboost` ([reference](http://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/), [long version reference](https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en))\n",
    "4. **tqdm**: type in anaconda command prompt: `pip install tqdm` ([reference](https://pypi.python.org/pypi/tqdm#usage))\n",
    "\n",
    "## Installing Keras, Tensorflow, CuDNN, Cuda Tool Kit\n",
    "*how to install keras, and the gpu supported version of tensorflow, as well as the entire GPU computing library*\n",
    "\n",
    "**Follow the instructions [here](https://github.com/3-musketeers/kaggle-dsb/blob/master/pipeline/build-simple-model/rough-draft/model_dependency_setup.md)**\n",
    "\n",
    "## Downloading Data\n",
    "**Follow the instructions [here](https://github.com/3-musketeers/kaggle-dsb/blob/master/pipeline/build-simple-model/rough-draft/model_data_setup.md)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Descriptions\n",
    "1. **numpy**: an extension to the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays\n",
    "2. **scikit-image** (skimage): collection of algorithms for image processing\n",
    "3. **scikit-learn**: simple and efficient tools for data mining and data analysis\n",
    "4. **keras** (tensorflow backend): high-level neural networks library, written in Python (runs on top of TensorFlow)\n",
    "5. **matplotlib**: a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms\n",
    "6. **pydicom** (dicom): pydicom is a pure python package for working with DICOM files such as medical images, reports, and radiotherapy objects\n",
    "7. **SimpleITK**: an open-source, cross-platform system that provides developers with an extensive suite of software tools for image analysis \n",
    "8. **pandas**: providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language\n",
    "9. **glob**: a module that finds all the pathnames matching a specified pattern according to the rules used by the Unix shell (results returned in arbitrary order)\n",
    "10. **csv**: a module that implements classes to read and write tabular data in CSV format\n",
    "11. **os**: a module that provides a portable way of using operating system dependent functionality\n",
    "12. **xgboost**: a library designed and optimized for boosting trees algorithms\n",
    "13. **pickle**: standard mechanism for object serialization\n",
    "14. **tqdm**: instantly make your loops show a smart progress meter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details:\n",
    "1. U-Net style convolutional network: to identify regions with nodules (U-net was designed for segmenting neuronal structures)\n",
    "2. appearance on nodules within the CT scan: indicate the possibility of cancer\n",
    "3. Lung Nodule Analysis 2016 (LUNA2016):\n",
    "   1. provides training examples with marked nodules in order train the U Net to find these nodules (CT images with annotated nodule locations)\n",
    "   2. use the LUNA data set to generate an appropriate training set for our U-Net\n",
    "   3. use these examples to train our supervised segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Training Set From LUNA16\n",
    "*goal:*\n",
    "\n",
    "Process:\n",
    "1. use the nodule locations as given in annotations.csv and extract three transverse slices that contain the largest nodule from each patient scan\n",
    "2. masks will be created for those slices based on the nodule dimensions given in annotations.csv\n",
    "3. output of this file will be two files for each patient scan: a set of images and a set of corresponding nodule masks\n",
    "\n",
    "\n",
    "* import tools\n",
    "* find largest nodule in the patient scan\n",
    "* use df_node (a pandas dataframe): to keep track of the case numbers and the node information (as there might be multiple nodule listings for some patients in annotations.csv)\n",
    "* node information is an (x,y,z) coordinate in mm using a coordinate system defined in the .mhd file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 10000000/10000000 [00:03<00:00, 2974410.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # will tqdm slow down the program significantly? if not then use it\n",
    "for i in tqdm(range(10000000)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import csv\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# path constants\n",
    "LUNA_DATA_PATH = '../../../../data/luna16/'\n",
    "LUNA_SUBSET_PATH = LUNA_DATA_PATH + 'subset0/'\n",
    "\n",
    "file_list = glob(LUNA_SUBSET_PATH + \"*.mhd\") # get all the mhd image files\n",
    "\n",
    "# Helper function to get rows in data frame associated with each file\n",
    "def get_filename(case):\n",
    "    global file_list\n",
    "    for f in file_list: # for every file in the list if the seriesuid is in the file name, return the file \n",
    "        if case in f:\n",
    "            return(f)\n",
    "\n",
    "# The locations of the nodes\n",
    "df_node = pd.read_csv(LUNA_DATA_PATH + \"annotations.csv\")\n",
    "df_node[\"file\"] = df_node[\"seriesuid\"].apply(get_filename) # for every rowsave file name to the 'file' column of the row\n",
    "df_node = df_node.dropna() # if the seriesuid is not found in this subset, drop all the rows that have na as values for 'file' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (00000214B1B0DA50)\n",
      "  RTTI typeinfo:   class itk::Image<short,3>\n",
      "  Reference Count: 1\n",
      "  Modified Time: 1060\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (none)\n",
      "  Source output name: (none)\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 1035\n",
      "  UpdateMTime: 1059\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 161]\n",
      "  BufferedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 161]\n",
      "  RequestedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 161]\n",
      "  Spacing: [0.548828, 0.548828, 1.25]\n",
      "  Origin: [-187.7, -108.3, -194]\n",
      "  Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "0.548828 0 0\n",
      "0 0.548828 0\n",
      "0 0 1.25\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "1.82206 0 0\n",
      "0 1.82206 0\n",
      "0 0 0.8\n",
      "\n",
      "  Inverse Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (00000214B1C224D0)\n",
      "      RTTI typeinfo:   class itk::ImportImageContainer<unsigned __int64,short>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 1056\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 00000214B2F8D040\n",
      "      Container manages memory: true\n",
      "      Size: 42205184\n",
      "      Capacity: 42205184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_file = file_list[2]\n",
    "itk_img = sitk.ReadImage(img_file) # using sitk to read a .mhd image\n",
    "print(itk_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " ..., \n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]]\n"
     ]
    }
   ],
   "source": [
    "# get the associated 3d pixel array for the .mhd image\n",
    "img_array = sitk.GetArrayFromImage(itk_img) # indexes are z,y,x (notice the ordering)\n",
    "print(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "seriesuid      1.3.6.1.4.1.14519.5.2.1.6279.6001.109002525524...\n",
      "coordX                                                   46.1885\n",
      "coordY                                                   48.4028\n",
      "coordZ                                                  -108.579\n",
      "diameter_mm                                              13.5965\n",
      "file           ../../../../data/luna16/subset0\\1.3.6.1.4.1.14...\n",
      "Name: 25, dtype: object\n",
      "26\n",
      "seriesuid      1.3.6.1.4.1.14519.5.2.1.6279.6001.109002525524...\n",
      "coordX                                                    36.392\n",
      "coordY                                                   76.7717\n",
      "coordZ                                                  -123.322\n",
      "diameter_mm                                               4.3432\n",
      "file           ../../../../data/luna16/subset0\\1.3.6.1.4.1.14...\n",
      "Name: 26, dtype: object\n"
     ]
    }
   ],
   "source": [
    "mini_df = df_node[df_node[\"file\"]==file_list[2]] # get all nodules associate with file\n",
    "for node_idx, cur_row in mini_df.iterrows():\n",
    "    print(node_idx)\n",
    "    print(cur_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "46.18853869\n",
      "48.40280596\n",
      "-108.5786324\n",
      "13.59647134\n",
      "\n",
      "\n",
      "[  46.18853869   48.40280596 -108.5786324 ]\n",
      "[-187.699997 -108.300003 -194.      ]\n",
      "[ 0.54882801  0.54882801  1.25      ]\n",
      "[ 426.  286.   68.]\n"
     ]
    }
   ],
   "source": [
    "biggest_node = np.argsort(mini_df[\"diameter_mm\"].values)[-1]\n",
    "node_x = mini_df[\"coordX\"].values[biggest_node]\n",
    "node_y = mini_df[\"coordY\"].values[biggest_node]\n",
    "node_z = mini_df[\"coordZ\"].values[biggest_node]\n",
    "diam = mini_df[\"diameter_mm\"].values[biggest_node]\n",
    "print(biggest_node)\n",
    "print(node_x)\n",
    "print(node_y)\n",
    "print(node_z)\n",
    "print(diam)\n",
    "print('\\n')\n",
    "\n",
    "center = np.array([node_x,node_y,node_z])   # nodule center\n",
    "origin = np.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "spacing = np.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "v_center =np.rint((center-origin)/spacing)  # nodule center in voxel space (still x,y,z ordering)\n",
    "\n",
    "print(center)\n",
    "print(origin)\n",
    "print(spacing)\n",
    "print(v_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
